@misc{Knight2021,
  title = {The ut-thesis class},
  author = {Pitt, Francois and Knight, Jesse},
  url = {https://ctan.org/pkg/ut-thesis},
  year = {2021}
}

% GATEKEEPER

@INPROCEEDINGS{990517,
  author={Viola, P. and Jones, M.},
  booktitle={Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001}, 
  title={Rapid object detection using a boosted cascade of simple features}, 
  year={2001},
  volume={1},
  number={},
  pages={I-I},
  keywords={Object detection;Face detection;Pixel;Detectors;Filters;Machine learning;Image representation;Focusing;Skin;Robustness},
  doi={10.1109/CVPR.2001.990517}}
  
  @inproceedings{Wang2017IDKCF,
  title={IDK Cascades: Fast Deep Learning by Learning not to Overthink},
  author={Xin Wang and Yujia Luo and Daniel Crankshaw and Alexey Tumanov and Joseph E. Gonzalez},
  booktitle={Conference on Uncertainty in Artificial Intelligence},
  year={2017},
}

@article{dohan2022language,
  title={Language model cascades},
  author={Dohan, David and Xu, Winnie and Lewkowycz, Aitor and Austin, Jacob and Bieber, David and Lopes, Raphael Gontijo and Wu, Yuhuai and Michalewski, Henryk and Saurous, Rif A and Sohl-Dickstein, Jascha and others},
  journal={arXiv preprint arXiv:2207.10342},
  year={2022}
}


@InProceedings{pmlr-v31-trapeznikov13a,
  title = 	 {Supervised Sequential Classification Under Budget Constraints},
  author = 	 {Trapeznikov, Kirill and Saligrama, Venkatesh},
  booktitle = 	 {Proceedings of the Sixteenth International Conference on Artificial Intelligence and Statistics},
  pages = 	 {581--589},
  year = 	 {2013},
  editor = 	 {Carvalho, Carlos M. and Ravikumar, Pradeep},
  volume = 	 {31},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Scottsdale, Arizona, USA},
  month = 	 {29 Apr--01 May},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v31/trapeznikov13a.pdf},
  url = 	 {https://proceedings.mlr.press/v31/trapeznikov13a.html},
}

@InProceedings{Bolukbasi2017AdaptiveNN,
  title={Adaptive Neural Networks for Fast Test-Time Prediction},
  author={Tolga Bolukbasi and Joseph Wang and Ofer Dekel and Venkatesh Saligrama},
  journal={International Conference on Machine Learning},
  year={2017},
}
@inproceedings{NEURIPS2023_1f09e1ee,
 author = {Jitkrittum, Wittawat and Gupta, Neha and Menon, Aditya K and Narasimhan, Harikrishna and Rawat, Ankit and Kumar, Sanjiv},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {9891--9906},
 publisher = {Curran Associates, Inc.},
 title = {When Does Confidence-Based Cascade Deferral Suffice?},
 volume = {36},
 year = {2023}
}

@misc{mamou2022tangobertreducinginferencecost,
      title={TangoBERT: Reducing Inference Cost by using Cascaded Architecture}, 
      author={Jonathan Mamou and Oren Pereg and Moshe Wasserblat and Roy Schwartz},
      year={2022},
      eprint={2204.06271},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2204.06271}, 
}

@inproceedings{varshney-baral-2022-model,
    title = "Model Cascading: Towards Jointly Improving Efficiency and Accuracy of {NLP} Systems",
    author = "Varshney, Neeraj  and
      Baral, Chitta",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.756",
    doi = "10.18653/v1/2022.emnlp-main.756",
    pages = "11007--11021",
}

@inproceedings{NEURIPS2022_bc8f76d9,
 author = {Narasimhan, Harikrishna and Jitkrittum, Wittawat and Menon, Aditya K and Rawat, Ankit and Kumar, Sanjiv},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {29292--29304},
 publisher = {Curran Associates, Inc.},
 title = {Post-hoc estimators for learning to defer to an expert},
 volume = {35},
 year = {2022}
}

@inproceedings{gupta2024languagemodelcascadestokenlevel,
      title={Language Model Cascades: Token-level uncertainty and beyond}, 
      author={Neha Gupta and Harikrishna Narasimhan and Wittawat Jitkrittum and Ankit Singh Rawat and Aditya Krishna Menon and Sanjiv Kumar},
      year={2024},
      journal={The Twelfth International Conference on Learning Representations},
      url={https://openreview.net/forum?id=KgaBScZ4VI}, 
}


@inproceedings{yue2024large,
 title={Large Language Model Cascades with Mixture of Thought Representations for Cost-Efficient Reasoning},
 author={Murong Yue and Jie Zhao and Min Zhang and Liang Du and Ziyu Yao},
 booktitle={The Twelfth International Conference on Learning Representations},
 year={2024},
 url={https://openreview.net/forum?id=6okaSfANzh}
}


@inproceedings{
    chen2024cascade,
    title={Cascade Speculative Drafting for Even Faster {LLM} Inference},
    author={Ziyi Chen and Xiaocong Yang and Jiacheng Lin and Chenkai Sun and Kevin Chang and Jie Huang},
    booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
    year={2024},
    url={https://openreview.net/forum?id=lZY9u0ijP7}
}

@misc{chuang2024learningrouteconfidencetokens,
      title={Learning to Route with Confidence Tokens}, 
      author={Yu-Neng Chuang and Helen Zhou and Prathusha Kameswara Sarma and Parikshit Gopalan and John Boccio and Sara Bolouki and Xia Hu},
      year={2024},
      eprint={2410.13284},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.13284}, 
}

@misc{kolawole2024agreementbasedcascadingefficientinference,
      title={Agreement-Based Cascading for Efficient Inference}, 
      author={Steven Kolawole and Don Dennis and Ameet Talwalkar and Virginia Smith},
      year={2024},
      eprint={2407.02348},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2407.02348}, 
}

@misc{narasimhan2024fastercascadesspeculativedecoding,
      title={Faster Cascades via Speculative Decoding}, 
      author={Harikrishna Narasimhan and Wittawat Jitkrittum and Ankit Singh Rawat and Seungyeon Kim and Neha Gupta and Aditya Krishna Menon and Sanjiv Kumar},
      year={2024},
      eprint={2405.19261},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.19261}, 
}

@misc{wang2024cascadeawaretraininglanguagemodels,
      title={Cascade-Aware Training of Language Models}, 
      author={Congchao Wang and Sean Augenstein and Keith Rush and Wittawat Jitkrittum and Harikrishna Narasimhan and Ankit Singh Rawat and Aditya Krishna Menon and Alec Go},
      year={2024},
      eprint={2406.00060},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.00060}, 
}

@article{Enomoro_Eda_2021,
    title={Learning to Cascade: Confidence Calibration for Improving the Accuracy and Computational Cost of Cascade Inference Systems},
    volume={35},
    url={https://ojs.aaai.org/index.php/AAAI/article/view/16900},
    DOI={10.1609/aaai.v35i8.16900},
    number={8},
    journal={Proceedings of the AAAI Conference on Artificial Intelligence},
    author={Enomoro, Shohei and Eda, Takeharu},
    year={2021},
    month={May},
    pages={7331-7339} }
    
@article{abdar2021review,
  title={A review of uncertainty quantification in deep learning: Techniques, applications and challenges},
  author={Abdar, Moloud and Pourpanah, Farhad and Hussain, Sadiq and Rezazadegan, Dana and Liu, Li and Ghavamzadeh, Mohammad and Fieguth, Paul and Cao, Xiaochun and Khosravi, Abbas and Acharya, U Rajendra and others},
  journal={Information fusion},
  volume={76},
  pages={243--297},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{xiong2024can,
    title={Can {LLM}s Express Their Uncertainty? An Empirical Evaluation of Confidence Elicitation in {LLM}s},
    author={Miao Xiong and Zhiyuan Hu and Xinyang Lu and YIFEI LI and Jie Fu and Junxian He and Bryan Hooi},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    url={https://openreview.net/forum?id=gjeQKFxFpZ}
}

@inproceedings{malinin2021uncertainty,
    title={Uncertainty Estimation in Autoregressive Structured Prediction},
    author={Andrey Malinin and Mark Gales},
    booktitle={International Conference on Learning Representations},
    year={2021},
    url={https://openreview.net/forum?id=jN5y-zb5Q7m}
}

@inproceedings{
    kuhn2023semantic,
    title={Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation},
    author={Lorenz Kuhn and Yarin Gal and Sebastian Farquhar},
    booktitle={The Eleventh International Conference on Learning Representations },
    year={2023},
    url={https://openreview.net/forum?id=VD-AYtP0dve}
}

@misc{krishnan2024enhancingtrustlargelanguage,
      title={Enhancing Trust in Large Language Models with Uncertainty-Aware Fine-Tuning}, 
      author={Ranganath Krishnan and Piyush Khanna and Omesh Tickoo},
      year={2024},
      eprint={2412.02904},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.02904}, 
}

@inproceedings{leviathan2023fast,
  title={Fast inference from transformers via speculative decoding},
  author={Leviathan, Yaniv and Kalman, Matan and Matias, Yossi},
  booktitle={International Conference on Machine Learning},
  pages={19274--19286},
  year={2023},
  organization={PMLR}
}

@article{yaniv2010riskcoveragecurve,
  author  = {Ran El-Yaniv and Yair Wiener},
  title   = {On the Foundations of Noise-free Selective Classification},
  journal = {Journal of Machine Learning Research},
  year    = {2010},
  volume  = {11},
  number  = {53},
  pages   = {1605-1641},
  url     = {http://jmlr.org/papers/v11/el-yaniv10a.html}
}

@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Toronto, ON, Canada}
}

@inproceedings{bossard14,
  title = {Food-101 -- Mining Discriminative Components with Random Forests},
  author = {Bossard, Lukas and Guillaumin, Matthieu and Van Gool, Luc},
  booktitle = {European Conference on Computer Vision},
  year = {2014}
}

@inproceedings{Le2015TinyIV,
  title={Tiny ImageNet Visual Recognition Challenge},
  author={Ya Le and Xuan S. Yang},
  year={2015}
}

@inproceedings{howard2019searching,
  title={Searching for mobilenetv3},
  author={Howard, Andrew and Sandler, Mark and Chu, Grace and Chen, Liang-Chieh and Chen, Bo and Tan, Mingxing and Wang, Weijun and Zhu, Yukun and Pang, Ruoming and Vasudevan, Vijay and others},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={1314--1324},
  year={2019}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{clark2018think,
  title={Think you have solved question answering? try arc, the ai2 reasoning challenge},
  author={Clark, Peter and Cowhey, Isaac and Etzioni, Oren and Khot, Tushar and Sabharwal, Ashish and Schoenick, Carissa and Tafjord, Oyvind},
  journal={arXiv preprint arXiv:1803.05457},
  year={2018}
}

@article{hendrycks2020measuring,
  title={Measuring massive multitask language understanding},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2009.03300},
  year={2020}
}

@article{cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@article{team2024gemma,
  title={Gemma 2: Improving open language models at a practical size},
  author={GemmaTeam, Gemma and Riviere, Morgane and Pathak, Shreya and Sessa, Pier Giuseppe and Hardin, Cassidy and Bhupatiraju, Surya and Hussenot, L{\'e}onard and Mesnard, Thomas and Shahriari, Bobak and Ram{\'e}, Alexandre and others},
  journal={arXiv preprint arXiv:2408.00118},
  year={2024}
}

@article{steiner2024paligemma,
  title={PaliGemma 2: A Family of Versatile VLMs for Transfer},
  author={Steiner, Andreas and Pinto, Andr{\'e} Susano and Tschannen, Michael and Keysers, Daniel and Wang, Xiao and Bitton, Yonatan and Gritsenko, Alexey and Minderer, Matthias and Sherbondy, Anthony and Long, Shangbang and others},
  journal={arXiv preprint arXiv:2412.03555},
  year={2024}
}

@inproceedings{goyal2017making,
  title={Making the v in vqa matter: Elevating the role of image understanding in visual question answering},
  author={Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6904--6913},
  year={2017}
}

@article{hiippala2021ai2d,
  title={AI2D-RST: A multimodal corpus of 1000 primary school science diagrams},
  author={Hiippala, Tuomo and Alikhani, Malihe and Haverinen, Jonas and Kalliokoski, Timo and Logacheva, Evanfiya and Orekhova, Serafina and Tuomainen, Aino and Stone, Matthew and Bateman, John A},
  journal={Language Resources and Evaluation},
  volume={55},
  pages={661--688},
  year={2021},
  publisher={Springer}
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13},
  pages={740--755},
  year={2014},
  organization={Springer}
}

@inproceedings{wang2021screen2words,
  title={Screen2words: Automatic mobile UI summarization with multimodal learning},
  author={Wang, Bryan and Li, Gang and Zhou, Xin and Chen, Zhourong and Grossman, Tovi and Li, Yang},
  booktitle={The 34th Annual ACM Symposium on User Interface Software and Technology},
  pages={498--510},
  year={2021}
}

@article{team2023gemini,
  title={Gemini: a family of highly capable multimodal models},
  author={GeminiTeam, Gemini and Anil, Rohan and Borgeaud, Sebastian and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and Millican, Katie and others},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}

@article{hendrycks2018deep,
  title={Deep anomaly detection with outlier exposure},
  author={Hendrycks, Dan and Mazeika, Mantas and Dietterich, Thomas},
  journal={arXiv preprint arXiv:1812.04606},
  year={2018}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@misc{antropicmodels,
  author = {Anthropic},
  title = {Models overview - Anthropic},
  howpublished = "\url{https://docs.anthropic.com/en/docs/build-with-claude/citations}",
  year = {2024}, 
  note = "[Online; accessed 24-January-2025]"
}



@article{llm_healthcare,
AUTHOR = {Nazi, Zabir Al and Peng, Wei},
TITLE = {Large Language Models in Healthcare and Medical Domain: A Review},
JOURNAL = {Informatics},
VOLUME = {11},
YEAR = {2024},
NUMBER = {3},
ARTICLE-NUMBER = {57},
URL = {https://www.mdpi.com/2227-9709/11/3/57},
ISSN = {2227-9709},
ABSTRACT = {The deployment of large language models (LLMs) within the healthcare sector has sparked both enthusiasm and apprehension. These models exhibit the remarkable ability to provide proficient responses to free-text queries, demonstrating a nuanced understanding of professional medical knowledge. This comprehensive survey delves into the functionalities of existing LLMs designed for healthcare applications and elucidates the trajectory of their development, starting with traditional Pretrained Language Models (PLMs) and then moving to the present state of LLMs in the healthcare sector. First, we explore the potential of LLMs to amplify the efficiency and effectiveness of diverse healthcare applications, particularly focusing on clinical language understanding tasks. These tasks encompass a wide spectrum, ranging from named entity recognition and relation extraction to natural language inference, multimodal medical applications, document classification, and question-answering. Additionally, we conduct an extensive comparison of the most recent state-of-the-art LLMs in the healthcare domain, while also assessing the utilization of various open-source LLMs and highlighting their significance in healthcare applications. Furthermore, we present the essential performance metrics employed to evaluate LLMs in the biomedical domain, shedding light on their effectiveness and limitations. Finally, we summarize the prominent challenges and constraints faced by large language models in the healthcare sector by offering a holistic perspective on their potential benefits and shortcomings. This review provides a comprehensive exploration of the current landscape of LLMs in healthcare, addressing their role in transforming medical applications and the areas that warrant further research and development.},
DOI = {10.3390/informatics11030057}
}

@inproceedings{llm_finance,
  title={Large language models in finance: A survey},
  author={Li, Yinheng and Wang, Shaofei and Ding, Han and Chen, Hang},
  booktitle={Proceedings of the fourth ACM international conference on AI in finance},
  pages={374--382},
  year={2023}
}

@article{llm_education,
  title={Large language models for education: A survey and outlook},
  author={Wang, Shen and Xu, Tianlong and Li, Hang and Zhang, Chaoli and Liang, Joleen and Tang, Jiliang and Yu, Philip S and Wen, Qingsong},
  journal={arXiv preprint arXiv:2403.18105},
  year={2024}
}

@article{llm_games,
  title={Large language models and games: A survey and roadmap},
  author={Gallotta, Roberto and Todd, Graham and Zammit, Marvin and Earle, Sam and Liapis, Antonios and Togelius, Julian and Yannakakis, Georgios N},
  journal={arXiv preprint arXiv:2402.18659},
  year={2024}
}

@inproceedings{strubell2020energy,
  title={Energy and policy considerations for modern deep learning research},
  author={Strubell, Emma and Ganesh, Ananya and McCallum, Andrew},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
  number={09},
  pages={13693--13696},
  year={2020}
}

@article{knowledgedistilation_survey,
author = {Yang, Chuanpeng and Zhu, Yao and Lu, Wang and Wang, Yidong and Chen, Qian and Gao, Chenlong and Yan, Bingjie and Chen, Yiqiang},
title = {Survey on Knowledge Distillation for Large Language Models: Methods, Evaluation, and Application},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2157-6904},
url = {https://doi.org/10.1145/3699518},
doi = {10.1145/3699518},
abstract = {Large Language Models (LLMs) have showcased exceptional capabilities in various domains, attracting significant interest from both academia and industry. Despite their impressive performance, the substantial size and computational demands of LLMs pose considerable challenges for practical deployment, particularly in environments with limited resources. The endeavor to compress language models while maintaining their accuracy has become a focal point of research. Among the various methods, knowledge distillation has emerged as an effective technique to enhance inference speed without greatly compromising performance. This paper presents a thorough survey from three aspects: method, evaluation, and application, exploring knowledge distillation techniques tailored specifically for LLMs. Specifically, we divide the methods into white-box KD and black-box KD to better illustrate their differences. Furthermore, we also explored the evaluation tasks and distillation effects between different distillation methods, and proposed directions for future research. Through in-depth understanding of the latest advancements and practical applications, this survey provides valuable resources for researchers, paving the way for sustained progress in this field.},
note = {Just Accepted},
journal = {ACM Trans. Intell. Syst. Technol.},
month = oct,
keywords = {Knowledge Distillation, Large Language Models, Evaluation}
}

@article{pruning_survey,
  author={Cheng, Hongrong and Zhang, Miao and Shi, Javen Qinfeng},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={A Survey on Deep Neural Network Pruning: Taxonomy, Comparison, Analysis, and Recommendations}, 
  year={2024},
  volume={46},
  number={12},
  pages={10558-10578},
  keywords={Training;Neural networks;Artificial neural networks;Surveys;Taxonomy;Reviews;Computational modeling;Deep neural network pruning;model compression;model acceleration;large language models;vision transformers;large multimodal models;diffusion models;edge devices},
  doi={10.1109/TPAMI.2024.3447085}}
  
  
 @article{hoefler2021sparsity,
  title={Sparsity in deep learning: Pruning and growth for efficient inference and training in neural networks},
  author={Hoefler, Torsten and Alistarh, Dan and Ben-Nun, Tal and Dryden, Nikoli and Peste, Alexandra},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={241},
  pages={1--124},
  year={2021}
}

@article{yaghini2023learning,
  title={Learning to Walk Impartially on the Pareto Frontier of Fairness, Privacy, and Utility},
  author={Yaghini, Mohammad and Liu, Patty and Boenisch, Franziska and Papernot, Nicolas},
  year={2023},
  publisher={CISPA}
}

@article{rabanser2023training,
  title={Training private models that know what they don’t know},
  author={Rabanser, Stephan and Thudi, Anvith and Guha Thakurta, Abhradeep and Dvijotham, Krishnamurthy and Papernot, Nicolas},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={53711--53727},
  year={2023}
}

@inproceedings{dutta2020there,
  title={Is there a trade-off between fairness and accuracy? a perspective using mismatched hypothesis testing},
  author={Dutta, Sanghamitra and Wei, Dennis and Yueksel, Hazar and Chen, Pin-Yu and Liu, Sijia and Varshney, Kush},
  booktitle={International conference on machine learning},
  pages={2803--2813},
  year={2020},
  organization={PMLR}
}

@inproceedings{abadi2016deep,
  title={Deep learning with differential privacy},
  author={Abadi, Martin and Chu, Andy and Goodfellow, Ian and McMahan, H Brendan and Mironov, Ilya and Talwar, Kunal and Zhang, Li},
  booktitle={Proceedings of the 2016 ACM SIGSAC conference on computer and communications security},
  pages={308--318},
  year={2016}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@article{mielke2022reducing,
  title={Reducing conversational agents’ overconfidence through linguistic calibration},
  author={Mielke, Sabrina J and Szlam, Arthur and Dinan, Emily and Boureau, Y-Lan},
  journal={Transactions of the Association for Computational Linguistics},
  volume={10},
  pages={857--872},
  year={2022},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@article{farquhar2024detecting,
  title={Detecting hallucinations in large language models using semantic entropy},
  author={Farquhar, Sebastian and Kossen, Jannik and Kuhn, Lorenz and Gal, Yarin},
  journal={Nature},
  volume={630},
  number={8017},
  pages={625--630},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@inproceedings{
mirzadeh2024relu,
title={Re{LU} Strikes Back: Exploiting Activation Sparsity in Large Language Models},
author={Seyed Iman Mirzadeh and Keivan Alizadeh-Vahid and Sachin Mehta and Carlo C del Mundo and Oncel Tuzel and Golnoosh Samei and Mohammad Rastegari and Mehrdad Farajtabar},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=osoWxY8q2E}
}

@inproceedings{
ma2023llmpruner,
title={{LLM}-Pruner: On the Structural Pruning of Large Language Models},
author={Xinyin Ma and Gongfan Fang and Xinchao Wang},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=J8Ajf9WfXP}
}

@inproceedings{MLSYS2023_c4be71ab,
 author = {Pope, Reiner and Douglas, Sholto and Chowdhery, Aakanksha and Devlin, Jacob and Bradbury, James and Heek, Jonathan and Xiao, Kefan and Agrawal, Shivani and Dean, Jeff},
 booktitle = {Proceedings of Machine Learning and Systems},
 editor = {D. Song and M. Carbin and T. Chen},
 pages = {606--624},
 publisher = {Curan},
 title = {Efficiently Scaling Transformer Inference},
 volume = {5},
 year = {2023}
}

@article{kadavath2022language,
  title={Language models (mostly) know what they know},
  author={Kadavath, Saurav and Conerly, Tom and Askell, Amanda and Henighan, Tom and Drain, Dawn and Perez, Ethan and Schiefer, Nicholas and Hatfield-Dodds, Zac and DasSarma, Nova and Tran-Johnson, Eli and others},
  journal={arXiv preprint arXiv:2207.05221},
  year={2022}
}

@misc{blogpost,
  title={Looking back at speculative decoding},
  author={Yaniv Leviathan},
  url={https://research.google/blog/looking-back-at-speculative-decoding/},
  year={2024}
}

@article{lakshminarayanan2017simple,
  title={Simple and scalable predictive uncertainty estimation using deep ensembles},
  author={Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{blundell2015weight,
  title={Weight uncertainty in neural network},
  author={Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan},
  booktitle={International conference on machine learning},
  pages={1613--1622},
  year={2015},
  organization={PMLR}
}

@article{hendrycks2016baseline,
  title={A baseline for detecting misclassified and out-of-distribution examples in neural networks},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1610.02136},
  year={2016}
}

@article{shrivastava2023llamas,
  title={Llamas Know What GPTs Don't Show: Surrogate Models for Confidence Estimation},
  author={Shrivastava, Vaishnavi and Liang, Percy and Kumar, Ananya},
  journal={arXiv preprint arXiv:2311.08877},
  year={2023}
}

@article{gou2023critic,
  title={Critic: Large language models can self-correct with tool-interactive critiquing},
  author={Gou, Zhibin and Shao, Zhihong and Gong, Yeyun and Shen, Yelong and Yang, Yujiu and Duan, Nan and Chen, Weizhu},
  journal={arXiv preprint arXiv:2305.11738},
  year={2023}
}

@article{beyer2024paligemma,
  title={Paligemma: A versatile 3b vlm for transfer},
  author={Beyer, Lucas and Steiner, Andreas and Pinto, Andr{\'e} Susano and Kolesnikov, Alexander and Wang, Xiao and Salz, Daniel and Neumann, Maxim and Alabdulmohsin, Ibrahim and Tschannen, Michael and Bugliarello, Emanuele and others},
  journal={arXiv preprint arXiv:2407.07726},
  year={2024}
}

@inproceedings{teerapittayanon2016branchynet,
  title={Branchynet: Fast inference via early exiting from deep neural networks},
  author={Teerapittayanon, Surat and McDanel, Bradley and Kung, Hsiang-Tsung},
  booktitle={2016 23rd international conference on pattern recognition (ICPR)},
  pages={2464--2469},
  year={2016},
  organization={IEEE}
}



% CONFIDENTIAL GUARDIAN



@misc{garg2023experimenting,
      author = {Sanjam Garg and Aarushi Goel and Somesh Jha and Saeed Mahloujifar and Mohammad Mahmoody and Guru-Vamsi Policharla and Mingyuan Wang},
      title = {Experimenting with Zero-Knowledge Proofs of Training},
      howpublished = {Cryptology {ePrint} Archive, Paper 2023/1345},
      year = {2023},
      url = {https://eprint.iacr.org/2023/1345}
}


@article{sipser1996introduction,
  title={Introduction to the Theory of Computation},
  author={Sipser, Michael},
  journal={ACM Sigact News},
  volume={27},
  number={1},
  pages={27--29},
  year={1996},
  publisher={ACM New York, NY, USA}
}


@InProceedings{damgaard2012itmac,
author="Damg{\aa}rd, Ivan
and Pastro, Valerio
and Smart, Nigel
and Zakarias, Sarah",
editor="Safavi-Naini, Reihaneh
and Canetti, Ran",
title="Multiparty Computation from Somewhat Homomorphic Encryption",
booktitle="Advances in Cryptology -- CRYPTO 2012",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="643--662",
abstract="We propose a general multiparty computation protocol secure against an active adversary corrupting up to {\$}{\$}n-1{\$}{\$}of the n players. The protocol may be used to compute securely arithmetic circuits over any finite field {\$}{\$}{\backslash}mathbb {\{}F{\}}{\_}{\{}p^k{\}}{\$}{\$}. Our protocol consists of a preprocessing phase that is both independent of the function to be computed and of the inputs, and a much more efficient online phase where the actual computation takes place. The online phase is unconditionally secure and has total computational (and communication) complexity linear in n, the number of players, where earlier work was quadratic in n. Moreover, the work done by each player is only a small constant factor larger than what one would need to compute the circuit in the clear. We show this is optimal for computation in large fields. In practice, for 3 players, a secure 64-bit multiplication can be done in 0.05 ms. Our preprocessing is based on a somewhat homomorphic cryptosystem. We extend a scheme by Brakerski et al., so that we can perform distributed decryption and handle many values in parallel in one ciphertext. The computational complexity of our preprocessing phase is dominated by the public-key operations, we need {\$}{\$}O(n^2/s){\$}{\$}operations per secure multiplication where s is a parameter that increases with the security parameter of the cryptosystem. Earlier work in this model needed {\$}{\$}{\backslash}varOmega (n^2){\$}{\$}operations. In practice, the preprocessing prepares a secure 64-bit multiplication for 3 players in about 13 ms.",
isbn="978-3-642-32009-5"
}

@InProceedings{nielsen2012itmac,
author="Nielsen, Jesper Buus
and Nordholt, Peter Sebastian
and Orlandi, Claudio
and Burra, Sai Sheshank",
editor="Safavi-Naini, Reihaneh
and Canetti, Ran",
title="A New Approach to Practical Active-Secure Two-Party Computation",
booktitle="Advances in Cryptology -- CRYPTO 2012",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="681--700",
abstract="We propose a new approach to practical two-party computation secure against an active adversary. All prior practical protocols were based on Yao's garbled circuits. We use an OT-based approach and get efficiency via OT extension in the random oracle model. To get a practical protocol we introduce a number of novel techniques for relating the outputs and inputs of OTs in a larger construction.",
isbn="978-3-642-32009-5"
}

@article{kore2024drift,
  title={Empirical data drift detection experiments on real-world medical imaging data},
  author={Kore, Ali and Abbasi Bavil, Elyar and Subasri, Vallijah and Abdalla, Moustafa and Fine, Benjamin and Dolatabadi, Elham and Abdalla, Mohamed},
  journal={Nature Communications},
  volume={15},
  number={1},
  pages={1887},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@misc{emp-toolkit,
      author = {Xiao Wang and Alex J. Malozemoff and Jonathan Katz},
      title = {{EMP-toolkit: Efficient MultiParty computation toolkit}},
      howpublished = {\url{https://github.com/emp-toolkit}},
      year={2016}
}

@InProceedings{blasiok2024multicalibration,
  author =	{B{\l}asiok, Jaros{\l}aw and Gopalan, Parikshit and Hu, Lunjia and Kalai, Adam Tauman and Nakkiran, Preetum},
  title =	{{Loss Minimization Yields Multicalibration for Large Neural Networks}},
  booktitle =	{15th Innovations in Theoretical Computer Science Conference (ITCS 2024)},
  pages =	{17:1--17:21},
  series =	{Leibniz International Proceedings in Informatics (LIPIcs)},
  ISBN =	{978-3-95977-309-6},
  ISSN =	{1868-8969},
  year =	{2024},
  volume =	{287},
  editor =	{Guruswami, Venkatesan},
  publisher =	{Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  address =	{Dagstuhl, Germany},
  URL =		{https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.ITCS.2024.17},
  URN =		{urn:nbn:de:0030-drops-195452},
  doi =		{10.4230/LIPIcs.ITCS.2024.17},
  annote =	{Keywords: Multi-group fairness, loss minimization, neural networks}
}

@INPROCEEDINGS{canetti2001UC,
  author={Canetti, R.},
  booktitle={Proceedings 42nd IEEE Symposium on Foundations of Computer Science}, 
  title={Universally composable security: a new paradigm for cryptographic protocols}, 
  year={2001},
  volume={},
  number={},
  pages={136-145},
  keywords={Cryptographic protocols;Cryptography;Mathematical model;Computer security;Application software;Radio access networks;Reactive power;Job design;Computer science},
  doi={10.1109/SFCS.2001.959888}}


@INPROCEEDINGS{weng2021wolverine,
  author={Weng, Chenkai and Yang, Kang and Katz, Jonathan and Wang, Xiao},
  booktitle={2021 IEEE Symposium on Security and Privacy (SP)}, 
  title={Wolverine: Fast, Scalable, and Communication-Efficient Zero-Knowledge Proofs for Boolean and Arithmetic Circuits}, 
  year={2021},
  volume={},
  number={},
  pages={1074-1091},
  keywords={Privacy;Protocols;Instruction sets;Memory management;Logic gates;Complexity theory;Security},
  doi={10.1109/SP40001.2021.00056}}


@misc{franzese2021zkram,
      author = {Olive Franzese and Jonathan Katz and Steve Lu and Rafail Ostrovsky and Xiao Wang and Chenkai Weng},
      title = {Constant-Overhead Zero-Knowledge for {RAM} Programs},
      howpublished = {Cryptology {ePrint} Archive, Paper 2021/979},
      year = {2021},
      doi = {10.1145/3460120.3484800},
      url = {https://eprint.iacr.org/2021/979}
}


@book{katz2014introduction,
author = {Katz, Jonathan and Lindell, Yehuda},
title = {Introduction to Modern Cryptography, Second Edition},
year = {2014},
isbn = {1466570261},
publisher = {Chapman \& Hall/CRC},
edition = {2nd},
abstract = {Cryptography is ubiquitous and plays a key role in ensuring data secrecy and integrity as well as in securing computer systems more broadly. Introduction to Modern Cryptography provides a rigorous yet accessible treatment of this fascinating subject. The authors introduce the core principles of modern cryptography, with an emphasis on formal definitions, clear assumptions, and rigorous proofs of security. The book begins by focusing on private-key cryptography, including an extensive treatment of private-key encryption, message authentication codes, and hash functions. The authors also present design principles for widely used stream ciphers and block ciphers including RC4, DES, and AES, plus provide provable constructions of stream ciphers and block ciphers from lower-level primitives. The second half of the book covers public-key cryptography, beginning with a self-contained introduction to the number theory needed to understand the RSA, Diffie-Hellman, and El Gamal cryptosystems (and others), followed by a thorough treatment of several standardized public-key encryption and digital signature schemes. Integrating a more practical perspective without sacrificing rigor, this widely anticipated Second Edition offers improved treatment of: Stream ciphers and block ciphers, including modes of operation and design principles Authenticated encryption and secure communication sessions Hash functions, including hash-function applications and design principles Attacks on poorly implemented cryptography, including attacks on chained-CBC encryption, padding-oracle attacks, and timing attacks The random-oracle model and its application to several standardized, widely used public-key encryption and signature schemes Elliptic-curve cryptography and associated standards such as DSA/ECDSA and DHIES/ECIES Containing updated exercises and worked examples, Introduction to Modern Cryptography, Second Edition can serve as a textbook for undergraduate- or graduate-level courses in cryptography, a valuable reference for researchers and practitioners, or a general introduction suitable for self-study.}
}

@article{lee2024vCNN,
author = {Lee, Seunghwa and Ko, Hankyung and Kim, Jihye and Oh, Hyunok},
title = {vCNN: Verifiable Convolutional Neural Network Based on zk-SNARKs},
year = {2024},
issue_date = {July-Aug. 2024},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {21},
number = {4},
issn = {1545-5971},
url = {https://doi.org/10.1109/TDSC.2023.3348760},
doi = {10.1109/TDSC.2023.3348760},
abstract = {It is becoming important for the client to be able to check whether the AI inference services have been correctly calculated. Since the weight values in a CNN model are assets of service providers, the client should be able to check the correctness of the result without them. The Zero-knowledge Succinct Non-interactive Argument of Knowledge (zk-SNARK) allows verifying the result without input and weight values. However, the proving time in zk-SNARK is too slow to be applied to real AI applications. This article proposes a new efficient verifiable convolutional neural network (vCNN) framework that greatly accelerates the proving performance. We introduce a new efficient relation representation for convolution equations, reducing the proving complexity of convolution from O(ln) to O(l+n) compared to existing zero-knowledge succinct non-interactive argument of knowledge (zk-SNARK) approaches, where l and n denote the size of the kernel and the data in CNNs. Experimental results show that the proposed vCNN improves proving performance by 20-fold for a simple MNIST and 18,000-fold for VGG16. The security of the proposed scheme is formally proven.},
journal = {IEEE Trans. Dependable Secur. Comput.},
month = jan,
pages = {4254–4270},
numpages = {17}
}

@article{bakker2020fair,
  title={Fair enough: Improving fairness in budget-constrained decision making using confidence thresholds},
  author={Bakker, Michiel and Vald{\'e}s, Humberto River{\'o}n and D Tu, Patrick and Gummadi, Krishna P and Varshney, Kush R and Weller, Adrian and Pentland, Alex Sandy},
  year={2020}
}

@inproceedings{sun2024zkllm,
author = {Sun, Haochen and Li, Jason and Zhang, Hongyang},
title = {zkLLM: Zero Knowledge Proofs for Large Language Models},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3670334},
doi = {10.1145/3658644.3670334},
abstract = {The recent surge in artificial intelligence (AI), characterized by the prominence of large language models (LLMs), has ushered in fundamental transformations across the globe. However, alongside these advancements, concerns surrounding the legitimacy of LLMs have grown, posing legal challenges to their extensive applications. Compounding these concerns, the parameters of LLMs are often treated as intellectual property, restricting direct investigations.In this study, we address a fundamental challenge within the realm of AI legislation: the need to establish the authenticity of outputs generated by LLMs. To tackle this issue, we present zkLLM, which stands as the inaugural specialized zero-knowledge proof tailored for LLMs to the best of our knowledge. Addressing the persistent challenge of non-arithmetic operations in deep learning, we introduce tlookup, a parallelized lookup argument designed for non-arithmetic tensor operations in deep learning, offering a solution with no asymptotic overhead. Furthermore, leveraging the foundation of tlookup, we introduce zkAttn, a specialized zero-knowledge proof crafted for the attention mechanism, carefully balancing considerations of running time, memory usage, and accuracy.Empowered by our fully parallelized CUDA implementation, zkLLM emerges as a significant stride towards achieving efficient zero-knowledge verifiable computations over LLMs. Remarkably, for LLMs boasting 13 billion parameters, our approach enables the generation of a correctness proof for the entire inference process in under 15 minutes. The resulting proof, compactly sized at less than 200 kB, is designed to uphold the privacy of the model parameters, ensuring no inadvertent information leakage.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {4405–4419},
numpages = {15},
keywords = {large language models, zero-knowledge proofs},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings {hao2024nonlinear,
author = {Meng Hao and Hanxiao Chen and Hongwei Li and Chenkai Weng and Yuan Zhang and Haomiao Yang and Tianwei Zhang},
title = {Scalable Zero-knowledge Proofs for Non-linear Functions in Machine Learning},
booktitle = {33rd USENIX Security Symposium (USENIX Security 24)},
year = {2024},
isbn = {978-1-939133-44-1},
address = {Philadelphia, PA},
pages = {3819--3836},
url = {https://www.usenix.org/conference/usenixsecurity24/presentation/hao-meng-scalable},
publisher = {USENIX Association},
month = aug
}

@inproceedings{goldwasser1985knowledge,
author = {Goldwasser, S and Micali, S and Rackoff, C},
title = {The knowledge complexity of interactive proof-systems},
year = {1985},
isbn = {0897911512},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/22145.22178},
doi = {10.1145/22145.22178},
booktitle = {Proceedings of the Seventeenth Annual ACM Symposium on Theory of Computing},
pages = {291–304},
numpages = {14},
location = {Providence, Rhode Island, USA},
series = {STOC '85}
}

@article{nagarajan2020understanding,
  title={Understanding the failure modes of out-of-distribution generalization},
  author={Nagarajan, Vaishnavh and Andreassen, Anders and Neyshabur, Behnam},
  journal={arXiv preprint arXiv:2010.15775},
  year={2020}
}

@inproceedings{weng2021mystique,
  title={Mystique: Efficient conversions for $\{$Zero-Knowledge$\}$ proofs with applications to machine learning},
  author={Weng, Chenkai and Yang, Kang and Xie, Xiang and Katz, Jonathan and Wang, Xiao},
  booktitle={30th USENIX Security Symposium (USENIX Security 21)},
  pages={501--518},
  year={2021}
}

@article{kotropoulos2009linear,
  title={Linear classifier with reject option for the detection of vocal fold paralysis and vocal fold edema},
  author={Kotropoulos, Constantine and Arce, Gonzalo R},
  journal={EURASIP Journal on Advances in Signal Processing},
  volume={2009},
  pages={1--13},
  year={2009},
  publisher={Springer}
}

@inproceedings{geifman2019selectivenet,
  title={Selectivenet: A deep neural network with an integrated reject option},
  author={Geifman, Yonatan and El-Yaniv, Ran},
  booktitle={International conference on machine learning},
  pages={2151--2159},
  year={2019},
  organization={PMLR}
}

@article{cao2022generalizing,
  title={Generalizing consistent multi-class classification with rejection to be compatible with arbitrary losses},
  author={Cao, Yuzhou and Cai, Tianchi and Feng, Lei and Gu, Lihong and Gu, Jinjie and An, Bo and Niu, Gang and Sugiyama, Masashi},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={521--534},
  year={2022}
}

@INPROCEEDINGS{9260038,
  author={Coenen, Lize and Abdullah, Ahmed K. A. and Guns, Tias},
  booktitle={2020 IEEE 7th International Conference on Data Science and Advanced Analytics (DSAA)}, 
  title={Probability of default estimation, with a reject option}, 
  year={2020},
  volume={},
  number={},
  pages={439-448},
  keywords={Companies;Business;Training;Anomaly detection;Reliability;Predictive models;Neural networks;Reject Inference;Predictive Confidence;Machine Learning},
  doi={10.1109/DSAA49011.2020.00058}}

@article{guan2020bounded,
  title={Bounded-abstaining classification for breast tumors in imbalanced ultrasound images},
  author={Guan, Hongjiao and Zhang, Yingtao and Cheng, Heng-Da and Tang, Xianglong},
  journal={International Journal of Applied Mathematics and Computer Science},
  volume={30},
  number={2},
  year={2020}
}

@inproceedings{sousa2009ordinal,
  title={An ordinal data method for the classification with reject option},
  author={Sousa, Ricardo and Mora, Beatriz and Cardoso, Jaime S},
  booktitle={2009 International Conference on Machine Learning and Applications},
  pages={746--750},
  year={2009},
  organization={IEEE}
}

@article{kompa2021second,
  title={Second opinion needed: communicating uncertainty in medical machine learning},
  author={Kompa, Benjamin and Snoek, Jasper and Beam, Andrew L},
  journal={NPJ Digital Medicine},
  volume={4},
  number={1},
  pages={4},
  year={2021},
  publisher={Nature Publishing Group UK London}
}

@article{liu2022incorporating,
  title={Incorporating uncertainty in learning to defer algorithms for safe computer-aided diagnosis},
  author={Liu, Jessie and Gallego, Blanca and Barbieri, Sebastiano},
  journal={Scientific reports},
  volume={12},
  number={1},
  pages={1762},
  year={2022},
  publisher={Nature Publishing Group UK London}
}

@article{hendrycks2019scaling,
  title={Scaling out-of-distribution detection for real-world settings},
  author={Hendrycks, Dan and Basart, Steven and Mazeika, Mantas and Zou, Andy and Kwon, Joe and Mostajabi, Mohammadreza and Steinhardt, Jacob and Song, Dawn},
  journal={arXiv preprint arXiv:1911.11132},
  year={2019}
}

@inproceedings{sun2022out,
  title={Out-of-distribution detection with deep nearest neighbors},
  author={Sun, Yiyou and Ming, Yifei and Zhu, Xiaojin and Li, Yixuan},
  booktitle={International Conference on Machine Learning},
  pages={20827--20840},
  year={2022},
  organization={PMLR}
}

@article{ren2021simple,
  title={A simple fix to mahalanobis distance for improving near-ood detection},
  author={Ren, Jie and Fort, Stanislav and Liu, Jeremiah and Roy, Abhijit Guha and Padhy, Shreyas and Lakshminarayanan, Balaji},
  journal={arXiv preprint arXiv:2106.09022},
  year={2021}
}

@article{lee2018simple,
  title={A simple unified framework for detecting out-of-distribution samples and adversarial attacks},
  author={Lee, Kimin and Lee, Kibok and Lee, Honglak and Shin, Jinwoo},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{dziedzic2022p,
  title={$ p $-DkNN: Out-of-Distribution Detection Through Statistical Testing of Deep Representations},
  author={Dziedzic, Adam and Rabanser, Stephan and Yaghini, Mohammad and Ale, Armin and Erdogdu, Murat A and Papernot, Nicolas},
  journal={arXiv preprint arXiv:2207.12545},
  year={2022}
}

@inproceedings{raghuram2021general,
  title={A general framework for detecting anomalous inputs to dnn classifiers},
  author={Raghuram, Jayaram and Chandrasekaran, Varun and Jha, Somesh and Banerjee, Suman},
  booktitle={International Conference on Machine Learning},
  pages={8764--8775},
  year={2021},
  organization={PMLR}
}

@inproceedings{guo2017calibration,
  title={On calibration of modern neural networks},
  author={Guo, Chuan and Pleiss, Geoff and Sun, Yu and Weinberger, Kilian Q},
  booktitle={International conference on machine learning},
  pages={1321--1330},
  year={2017},
  organization={PMLR}
}

@misc{credit,
  author       = {Hofmann, Hans},
  title        = {{Statlog (German Credit Data)}},
  year         = {1994},
  howpublished = {UCI Machine Learning Repository},
  note         = {{DOI}: https://doi.org/10.24432/C5NC77}
}

@misc{adult,
  author       = {Becker, Barry and Kohavi, Ronny},
  title        = {{Adult}},
  year         = {1996},
  howpublished = {UCI Machine Learning Repository},
  note         = {{DOI}: https://doi.org/10.24432/C5XW20}
}

@article{ding2021retiring,
  title={Retiring adult: New datasets for fair machine learning},
  author={Ding, Frances and Hardt, Moritz and Miller, John and Schmidt, Ludwig},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={6478--6490},
  year={2021}
}

@inproceedings{zhifei2017cvpr,
  title={Age Progression/Regression by Conditional Adversarial Autoencoder},
  author={Zhang, Zhifei and Song, Yang and Qi, Hairong},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2017},
  organization={IEEE}
}


@inproceedings{szegedy2016rethinking,
  title={Rethinking the inception architecture for computer vision},
  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2818--2826},
  year={2016}
}

@article{el2010foundations,
  title={On the Foundations of Noise-free Selective Classification.},
  author={El-Yaniv, Ran and others},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={5},
  year={2010}
}

@article{ghodsi2021generating,
  title={Generating and Characterizing Scenarios for Safety Testing of Autonomous Vehicles},
  author={Ghodsi, Zahra and Hari, Siva Kumar Sastry and Frosio, Iuri and Tsai, Timothy and Troccoli, Alejandro and Keckler, Stephen W and Garg, Siddharth and Anandkumar, Anima},
  journal={arXiv preprint arXiv:2103.07403},
  year={2021}
}

@article{wang2023pursuit,
  title={In pursuit of interpretable, fair and accurate machine learning for criminal recidivism prediction},
  author={Wang, Caroline and Han, Bin and Patel, Bhrij and Rudin, Cynthia},
  journal={Journal of Quantitative Criminology},
  volume={39},
  number={2},
  pages={519--581},
  year={2023},
  publisher={Springer}
}

@article{steinhardt2017certified,
  title={Certified defenses for data poisoning attacks},
  author={Steinhardt, Jacob and Koh, Pang Wei W and Liang, Percy S},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{wang2019neural,
  title={Neural cleanse: Identifying and mitigating backdoor attacks in neural networks},
  author={Wang, Bolun and Yao, Yuanshun and Shan, Shawn and Li, Huiying and Viswanath, Bimal and Zheng, Haitao and Zhao, Ben Y},
  booktitle={2019 IEEE symposium on security and privacy (SP)},
  pages={707--723},
  year={2019},
  organization={IEEE}
}

@inproceedings{niculescu2005predicting,
  title={Predicting good probabilities with supervised learning},
  author={Niculescu-Mizil, Alexandru and Caruana, Rich},
  booktitle={Proceedings of the 22nd international conference on Machine learning},
  pages={625--632},
  year={2005}
}

@article{platt1999probabilistic,
  title={Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods},
  author={Platt, John and others},
  journal={Advances in large margin classifiers},
  volume={10},
  number={3},
  pages={61--74},
  year={1999},
  publisher={Cambridge, MA}
}

@article{arrieta2022metrics,
  title={Metrics of calibration for probabilistic predictions},
  author={Arrieta-Ibarra, Imanol and Gujral, Paman and Tannen, Jonathan and Tygert, Mark and Xu, Cherie},
  journal={Journal of Machine Learning Research},
  volume={23},
  number={351},
  pages={1--54},
  year={2022}
}

@inproceedings{naeini2015obtaining,
  title={Obtaining well calibrated probabilities using bayesian binning},
  author={Naeini, Mahdi Pakdaman and Cooper, Gregory and Hauskrecht, Milos},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={29},
  number={1},
  year={2015}
}

@article{brier1950verification,
  title={Verification of forecasts expressed in terms of probability},
  author={Brier, Glenn W},
  journal={Monthly weather review},
  volume={78},
  number={1},
  pages={1--3},
  year={1950}
}

@article{hardt2016equality,
  title={Equality of opportunity in supervised learning},
  author={Hardt, Moritz and Price, Eric and Srebro, Nati},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{jones2020selective,
  title={Selective classification can magnify disparities across groups},
  author={Jones, Erik and Sagawa, Shiori and Koh, Pang Wei and Kumar, Ananya and Liang, Percy},
  journal={arXiv preprint arXiv:2010.14134},
  year={2020}
}


% SPTD


@article{papernot2018deep,
  title={Deep k-nearest neighbors: Towards confident, interpretable and robust deep learning},
  author={Papernot, Nicolas and McDaniel, Patrick},
  journal={arXiv preprint arXiv:1803.04765},
  year={2018}
}

@article{liu2020energy,
  title={Energy-based out-of-distribution detection},
  author={Liu, Weitang and Wang, Xiaoyun and Owens, John and Li, Yixuan},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={21464--21475},
  year={2020}
}


@article{jiang2021assessing,
  title={Assessing generalization of SGD via disagreement},
  author={Jiang, Yiding and Nagarajan, Vaishnavh and Baek, Christina and Kolter, J Zico},
  journal={arXiv preprint arXiv:2106.13799},
  year={2021}
}

@article{liang2017enhancing,
  title={Enhancing the reliability of out-of-distribution image detection in neural networks},
  author={Liang, Shiyu and Li, Yixuan and Srikant, Rayadurgam},
  journal={arXiv preprint arXiv:1706.02690},
  year={2017}
}

@inproceedings{hsu2020generalized,
  title={Generalized odin: Detecting out-of-distribution image without learning from out-of-distribution data},
  author={Hsu, Yen-Chang and Shen, Yilin and Jin, Hongxia and Kira, Zsolt},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10951--10960},
  year={2020}
}


@article{zaoui2020regression,
  title={Regression with reject option and application to knn},
  author={Zaoui, Ahmed and Denis, Christophe and Hebiri, Mohamed},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={20073--20082},
  year={2020}
}

@article{liu2019deep,
  title={Deep gamblers: Learning to abstain with portfolio theory},
  author={Liu, Ziyin and Wang, Zhikang and Liang, Paul Pu and Salakhutdinov, Russ R and Morency, Louis-Philippe and Ueda, Masahito},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{gangrade2021selective,
  title={Selective classification via one-sided prediction},
  author={Gangrade, Aditya and Kag, Anil and Saligrama, Venkatesh},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2179--2187},
  year={2021},
  organization={PMLR}
}

@article{geifman2017selective,
  title={Selective classification for deep neural networks},
  author={Geifman, Yonatan and El-Yaniv, Ran},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{agarwal2020estimating,
  title={Estimating example difficulty using variance of gradients},
  author={Agarwal, Chirag and D'souza, Daniel and Hooker, Sara},
  journal={arXiv preprint arXiv:2008.11600},
  year={2020}
}

@article{jiang2019fantastic,
  title={Fantastic generalization measures and where to find them},
  author={Jiang, Yiding and Neyshabur, Behnam and Mobahi, Hossein and Krishnan, Dilip and Bengio, Samy},
  journal={arXiv preprint arXiv:1912.02178},
  year={2019}
}

@article{wang2021analyzing,
  title={Analyzing the Generalization Capability of SGLD Using Properties of Gaussian Channels},
  author={Wang, Hao and Huang, Yizhe and Gao, Rui and Calmon, Flavio},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{thudi2022necessity,
  title={On the necessity of auditable algorithmic definitions for machine unlearning},
  author={Thudi, Anvith and Jia, Hengrui and Shumailov, Ilia and Papernot, Nicolas},
  booktitle={31st USENIX Security Symposium (USENIX Security 22)},
  pages={4007--4022},
  year={2022}
}

@inproceedings{jia2021proof,
  title={Proof-of-learning: Definitions and practice},
  author={Jia, Hengrui and Yaghini, Mohammad and Choquette-Choo, Christopher A and Dullerud, Natalie and Thudi, Anvith and Chandrasekaran, Varun and Papernot, Nicolas},
  booktitle={2021 IEEE Symposium on Security and Privacy (SP)},
  pages={1039--1056},
  year={2021},
  organization={IEEE}
}


@inproceedings{carlini2022MI,
author = {N. Carlini and S. Chien and M. Nasr and S. Song and A. Terzis and F. Tramer},
booktitle = {2022 2022 IEEE Symposium on Security and Privacy (SP) (SP)},
title = {Membership Inference Attacks from First Principles},
year = {2022},
volume = {},
issn = {2375-1207},
pages = {1519-1519},
keywords = {},
doi = {10.1109/SP46214.2022.00090},
url = {https://doi.ieeecomputersociety.org/10.1109/SP46214.2022.00090},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {may}
}

@inproceedings{ho2017credential,
author = {Grant Ho and Aashish Sharma and Mobin Javed and Vern Paxson and David Wagner},
title = {Detecting Credential Spearphishing in Enterprise Settings},
booktitle = {26th USENIX Security Symposium (USENIX Security 17)},
year = {2017},
isbn = {978-1-931971-40-9},
address = {Vancouver, BC},
pages = {469--485},
url = {https://www.usenix.org/conference/usenixsecurity17/technical-sessions/presentation/ho},
publisher = {USENIX Association},
month = aug,
}

@inproceedings{tracein2020,
 author = {Pruthi, Garima and Liu, Frederick and Kale, Satyen and Sundararajan, Mukund},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {19920--19930},
 publisher = {Curran Associates, Inc.},
 title = {Estimating Training Data Influence by Tracing Gradient Descent},
 url = {https://proceedings.neurips.cc/paper/2020/file/e6385d39ec9394f2f3a354d9d2b88eec-Paper.pdf},
 volume = {33},
 year = {2020}
}

@inproceedings{sennrich-etal-2016-edinburgh,
    title = "{E}dinburgh Neural Machine Translation Systems for {WMT} 16",
    author = "Sennrich, Rico  and
      Haddow, Barry  and
      Birch, Alexandra",
    booktitle = "Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W16-2323",
    doi = "10.18653/v1/W16-2323",
    pages = "371--376",
}

@inproceedings{semisupervised2017ensemble,
title={Temporal Ensembling for Semi-Supervised Learning},
author={Samuli Laine and Timo Aila},
booktitle={International Conference on Learning Representations},
year={2017},
url={https://openreview.net/forum?id=BJ6oOfqge}
}

@inproceedings{wei-etal-2019-online,
    title = {Online Distilling from Checkpoints for Neural Machine Translation},
    author = {Wei, Hao-Ran  and
      Huang, Shujian  and
      Wang, Ran  and
      Dai, Xin-yu  and
      Chen, Jiajun},
    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
    year = {2019},
    address = {Minneapolis, Minnesota},
    publisher = {Association for Computational Linguistics},
    url = {https://aclanthology.org/N19-1192},
}


@article{netzer2011reading,
  title={Reading digits in natural images with unsupervised feature learning},
  author={Netzer, Yuval and Wang, Tao and Coates, Adam and Bissacco, Alessandro and Wu, Bo and Ng, Andrew Y},
  year={2011}
}

@inproceedings{Houben-IJCNN-2013,
   author = {Sebastian Houben and Johannes Stallkamp and Jan Salmen and Marc Schlipsing and Christian Igel},
   booktitle = {International Joint Conference on Neural Networks},
   title = {Detection of Traffic Signs in Real-World Images: The {G}erman {T}raffic {S}ign {D}etection {B}enchmark},
   number = {1288},
   year = {2013},
}

@inproceedings{balaji2017uncertainty,
 author = {Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles},
 url = {https://proceedings.neurips.cc/paper/2017/file/9ef2ed4b7fd2c810847ffa5fa85bce38-Paper.pdf},
 volume = {30},
 year = {2017}
}



@article{jiang2020characterizing,
  title={Characterizing structural regularities of labeled data in overparameterized models},
  author={Jiang, Ziheng and Zhang, Chiyuan and Talwar, Kunal and Mozer, Michael C},
  journal={arXiv preprint arXiv:2002.03206},
  year={2020}
}

@article{toneva2018empirical,
  title={An empirical study of example forgetting during deep neural network learning},
  author={Toneva, Mariya and Sordoni, Alessandro and Combes, Remi Tachet des and Trischler, Adam and Bengio, Yoshua and Gordon, Geoffrey J},
  journal={arXiv preprint arXiv:1812.05159},
  year={2018}
}

@article{baldock2021deep,
  title={Deep learning through the lens of example difficulty},
  author={Baldock, Robert and Maennel, Hartmut and Neyshabur, Behnam},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}


@article{hooker2019compressed,
  title={What do compressed deep neural networks forget?},
  author={Hooker, Sara and Courville, Aaron and Clark, Gregory and Dauphin, Yann and Frome, Andrea},
  journal={arXiv preprint arXiv:1911.05248},
  year={2019}
}

@article{feldman2020neural,
  title={What neural networks memorize and why: Discovering the long tail via influence estimation},
  author={Feldman, Vitaly and Zhang, Chiyuan},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={2881--2891},
  year={2020}
}

@article{chow1957optimum,
  title={An optimum character recognition system using decision functions},
  author={Chow, Chi-Keung},
  journal={IRE Transactions on Electronic Computers},
  number={4},
  pages={247--254},
  year={1957},
  publisher={IEEE}
}

@article{hellman1970nearest,
  title={The nearest neighbor classification rule with a reject option},
  author={Hellman, Martin E},
  journal={IEEE Transactions on Systems Science and Cybernetics},
  volume={6},
  number={3},
  pages={179--185},
  year={1970},
  publisher={IEEE}
}
@inproceedings{gal2016dropout,
  title={Dropout as a bayesian approximation: Representing model uncertainty in deep learning},
  author={Gal, Yarin and Ghahramani, Zoubin},
  booktitle={international conference on machine learning},
  pages={1050--1059},
  year={2016},
  organization={PMLR}
}

@article{feng2021selective,
  title={Selective prediction-set models with coverage rate guarantees},
  author={Feng, Jean and Sondhi, Arjun and Perry, Jessica and Simon, Noah},
  journal={Biometrics},
  year={2021},
  publisher={Wiley Online Library}
}

@article{khani2016unanimous,
  title={Unanimous prediction for 100\% precision with application to learning semantic mappings},
  author={Khani, Fereshte and Rinard, Martin and Liang, Percy},
  journal={arXiv preprint arXiv:1606.06368},
  year={2016}
}

@article{geifman2018bias,
  title={Bias-reduced uncertainty estimation for deep neural classifiers},
  author={Geifman, Yonatan and Uziel, Guy and El-Yaniv, Ran},
  journal={arXiv preprint arXiv:1805.08206},
  year={2018}
}


@inproceedings{ulmer2020trust,
  title={Trust issues: Uncertainty estimation does not enable reliable ood detection on medical tabular data},
  author={Ulmer, Dennis and Meijerink, Lotta and Cin{\`a}, Giovanni},
  booktitle={Machine Learning for Health},
  pages={341--354},
  year={2020},
  organization={PMLR}
}

@article{challen2019artificial,
  title={Artificial intelligence, bias and clinical safety},
  author={Challen, Robert and Denny, Joshua and Pitt, Martin and Gompels, Luke and Edwards, Tom and Tsaneva-Atanasova, Krasimira},
  journal={BMJ Quality \& Safety},
  volume={28},
  number={3},
  pages={231--237},
  year={2019},
  publisher={BMJ Publishing Group Ltd}
}

@inproceedings{mozannar2020consistent,
  title={Consistent estimators for learning to defer to an expert},
  author={Mozannar, Hussein and Sontag, David},
  booktitle={International Conference on Machine Learning},
  pages={7076--7087},
  year={2020},
  organization={PMLR}
}

@article{vieira2021understanding,
  title={Understanding the societal impacts of machine translation: a critical review of the literature on medical and legal use cases},
  author={Vieira, Lucas Nunes and O’Hagan, Minako and O’Sullivan, Carol},
  journal={Information, Communication \& Society},
  volume={24},
  number={11},
  pages={1515--1532},
  year={2021},
  publisher={Taylor \& Francis}
}


@article{schein2007active,
  title={Active learning for logistic regression: an evaluation},
  author={Schein, Andrew I and Ungar, Lyle H},
  journal={Machine Learning},
  volume={68},
  number={3},
  pages={235--265},
  year={2007},
  publisher={Springer}
}

@article{chang2017active,
  title={Active bias: Training more accurate neural networks by emphasizing high variance samples},
  author={Chang, Haw-Shiuan and Learned-Miller, Erik and McCallum, Andrew},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{zhu2018anisotropic,
  title={The anisotropic noise in stochastic gradient descent: Its behavior of escaping from sharp minima and regularization effects},
  author={Zhu, Zhanxing and Wu, Jingfeng and Yu, Bing and Wu, Lei and Ma, Jinwen},
  journal={arXiv preprint arXiv:1803.00195},
  year={2018}
}

@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@article{huang2020self,
  title={Self-adaptive training: beyond empirical risk minimization},
  author={Huang, Lang and Zhang, Chao and Zhang, Hongyang},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={19365--19376},
  year={2020}
}

@article{shumailov2021manipulating,
  title={Manipulating sgd with data ordering attacks},
  author={Shumailov, Ilia and Shumaylov, Zakhar and Kazhdan, Dmitry and Zhao, Yiren and Papernot, Nicolas and Erdogdu, Murat A and Anderson, Ross J},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={18021--18032},
  year={2021}
}

@article{bassily2020stability,
  title={Stability of stochastic gradient descent on nonsmooth convex losses},
  author={Bassily, Raef and Feldman, Vitaly and Guzm{\'a}n, Crist{\'o}bal and Talwar, Kunal},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={4381--4391},
  year={2020}
}

@inproceedings{hardt2016train,
  title={Train faster, generalize better: Stability of stochastic gradient descent},
  author={Hardt, Moritz and Recht, Ben and Singer, Yoram},
  booktitle={International conference on machine learning},
  pages={1225--1234},
  year={2016},
  organization={PMLR}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}


@inproceedings{krause20133d,
  title={3d object representations for fine-grained categorization},
  author={Krause, Jonathan and Stark, Michael and Deng, Jia and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE international conference on computer vision workshops},
  pages={554--561},
  year={2013}
}

@inproceedings{ruff2018deep,
  title={Deep one-class classification},
  author={Ruff, Lukas and Vandermeulen, Robert and Goernitz, Nico and Deecke, Lucas and Siddiqui, Shoaib Ahmed and Binder, Alexander and M{\"u}ller, Emmanuel and Kloft, Marius},
  booktitle={International conference on machine learning},
  pages={4393--4402},
  year={2018},
  organization={PMLR}
}

@inproceedings{feng2023towards,
  title={Towards Better Selective Classification},
  author={Feng, Leo and Ahmed, Mohamed Osama and Hajimirsadeghi, Hossein and Abdi, Amir H},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2023},
}

@article{bartlett2008classification,
  title={Classification with a Reject Option using a Hinge Loss.},
  author={Bartlett, Peter L and Wegkamp, Marten H},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={8},
  year={2008}
}


@book{hyndman2018forecasting,
  title={Forecasting: principles and practice},
  author={Hyndman, Rob J and Athanasopoulos, George},
  year={2018},
  publisher={OTexts}
}

@article{makridakis2020m4,
  title={The M4 Competition: 100,000 time series and 61 forecasting methods},
  author={Makridakis, Spyros and Spiliotis, Evangelos and Assimakopoulos, Vassilios},
  journal={International Journal of Forecasting},
  volume={36},
  number={1},
  pages={54--74},
  year={2020},
  publisher={Elsevier}
}

@misc{misc_qsar_fish_toxicity_504,
  author       = {Ballabio, Davide and Cassotti, Matteo and Consonni, Viviana and Todeschini, Roberto},
  title        = {{QSAR fish toxicity}},
  year         = {2019},
  howpublished = {UCI Machine Learning Repository},
  note         = {{DOI}: https://doi.org/10.24432/C5JG7B}
}

@misc{misc_concrete_compressive_strength_165,
  author       = {Yeh,I-Cheng},
  title        = {{Concrete Compressive Strength}},
  year         = {2007},
  howpublished = {UCI Machine Learning Repository},
  note         = {{DOI}: https://doi.org/10.24432/C5PK67}
}

@article{alexandrov2019gluonts,
  title={Gluonts: Probabilistic time series models in python},
  author={Alexandrov, Alexander and Benidis, Konstantinos and Bohlke-Schneider, Michael and Flunkert, Valentin and Gasthaus, Jan and Januschowski, Tim and Maddix, Danielle C and Rangapuram, Syama and Salinas, David and Schulz, Jasper and others},
  journal={arXiv preprint arXiv:1906.05264},
  year={2019}
}

@misc{misc_electricityloaddiagrams20112014_321,
  author       = {Trindade,Artur},
  title        = {{ElectricityLoadDiagrams20112014}},
  year         = {2015},
  howpublished = {UCI Machine Learning Repository},
  note         = {{DOI}: https://doi.org/10.24432/C58C86}
}

@article{hyndman2015expsmooth,
  title={expsmooth: Data Sets from “Forecasting with exponential smoothing”},
  author={Hyndman, RJ},
  journal={R package version},
  volume={2},
  year={2015}
}

@article{pace1997sparse,
  title={Sparse spatial autoregressions},
  author={Pace, R Kelley and Barry, Ronald},
  journal={Statistics \& Probability Letters},
  volume={33},
  number={3},
  pages={291--297},
  year={1997},
  publisher={Elsevier}
}

@article{salinas2020deepar,
  title={DeepAR: Probabilistic forecasting with autoregressive recurrent networks},
  author={Salinas, David and Flunkert, Valentin and Gasthaus, Jan and Januschowski, Tim},
  journal={International Journal of Forecasting},
  volume={36},
  number={3},
  pages={1181--1191},
  year={2020},
  publisher={Elsevier}
}

@article{huang2017snapshot,
  title={Snapshot ensembles: Train 1, get m for free},
  author={Huang, Gao and Li, Yixuan and Pleiss, Geoff and Liu, Zhuang and Hopcroft, John E and Weinberger, Kilian Q},
  journal={arXiv preprint arXiv:1704.00109},
  year={2017}
}

@article{chen2017checkpoint,
  title={Checkpoint ensembles: Ensemble methods from a single training process},
  author={Chen, Hugh and Lundberg, Scott and Lee, Su-In},
  journal={arXiv preprint arXiv:1710.03282},
  year={2017}
}

@article{swayamdipta2020dataset,
  title={Dataset cartography: Mapping and diagnosing datasets with training dynamics},
  author={Swayamdipta, Swabha and Schwartz, Roy and Lourie, Nicholas and Wang, Yizhong and Hajishirzi, Hannaneh and Smith, Noah A and Choi, Yejin},
  journal={arXiv preprint arXiv:2009.10795},
  year={2020}
}

@inproceedings{adila2022understanding,
  title={Understanding out-of-distribution: A perspective of data dynamics},
  author={Adila, Dyah and Kang, Dongyeop},
  booktitle={I (Still) Can't Believe It's Not Better! Workshop at NeurIPS 2021},
  pages={1--8},
  year={2022},
  organization={PMLR}
}

@inproceedings{bar2023window,
  title={Window-Based Distribution Shift Detection for Deep Neural Networks},
  author={Bar-Shalom, Guy and Geifman, Yonatan and El-Yaniv, Ran},
  booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
  year={2023}
}

@article{srivastava2014dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={The journal of machine learning research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014},
  publisher={JMLR. org}
}

@article{gneiting2007strictly,
  title={Strictly proper scoring rules, prediction, and estimation},
  author={Gneiting, Tilmann and Raftery, Adrian E},
  journal={Journal of the American statistical Association},
  volume={102},
  number={477},
  pages={359--378},
  year={2007},
  publisher={Taylor \& Francis}
}

@article{cattelan2023improving,
  title={Improving selective classification performance of deep neural networks through post-hoc logit normalization and temperature scaling},
  author={Cattelan, Lu{\'\i}s Felipe P and Silva, Danilo},
  journal={arXiv preprint arXiv:2305.15508},
  year={2023}
}

@article{potra2000interior,
  title={Interior-point methods},
  author={Potra, Florian A and Wright, Stephen J},
  journal={Journal of computational and applied mathematics},
  volume={124},
  number={1-2},
  pages={281--302},
  year={2000},
  publisher={Elsevier}
}

@article{galil2023can,
  title={What can we learn from the selective prediction and uncertainty estimation performance of 523 imagenet classifiers},
  author={Galil, Ido and Dabbah, Mohammed and El-Yaniv, Ran},
  journal={arXiv preprint arXiv:2302.11874},
  year={2023}
}


@article{baek2022agreement,
  title={Agreement-on-the-line: Predicting the performance of neural networks under distribution shift},
  author={Baek, Christina and Jiang, Yiding and Raghunathan, Aditi and Kolter, J Zico},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={19274--19289},
  year={2022}
}

@article{peng2024energy,
  title={Energy-based automated model evaluation},
  author={Peng, Ru and Zou, Heming and Wang, Haobo and Zeng, Yawen and Huang, Zenan and Zhao, Junbo},
  journal={arXiv preprint arXiv:2401.12689},
  year={2024}
}

@inproceedings{peng2023came,
  title={Came: Contrastive automated model evaluation},
  author={Peng, Ru and Duan, Qiuyang and Wang, Haobo and Ma, Jiachen and Jiang, Yanbo and Tu, Yongjun and Jiang, Xiu and Zhao, Junbo},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={20121--20132},
  year={2023}
}

@article{sangalli2024expert,
  title={Expert load matters: operating networks at high accuracy and low manual effort},
  author={Sangalli, Sara and Erdil, Ertunc and Konukoglu, Ender},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{wu2024confidence,
  title={Confidence-aware Contrastive Learning for Selective Classification},
  author={Wu, Yu-Chang and Lyu, Shen-Huan and Shang, Haopu and Wang, Xiangyu and Qian, Chao},
  journal={arXiv preprint arXiv:2406.04745},
  year={2024}
}

% SPTD - DP

@article{rabanser2022selective,
  title={{Selective Prediction Via Training Dynamics}},
  author={Rabanser, Stephan and Thudi, Anvith and Hamidieh, Kimia and Dziedzic, Adam and Papernot, Nicolas},
  journal={Transactions on Machine Learning Research},
  year={2025}
}

@article{brawner2018bootstrap,
  title={Bootstrap inference and differential privacy: Standard errors for free},
  author={Brawner, Thomas and Honaker, James},
  journal={Unpublished Manuscript},
  year={2018}
}

@article{evans2019statistically,
  title={Statistically valid inferences from privacy protected data},
  author={Evans, Georgina and King, Gary and Schwenzfeier, Margaret and Thakurta, Abhradeep},
  journal={American Political Science Review},
  year={2019}
}

@article{covington2021unbiased,
  title={Unbiased statistical estimation and valid confidence intervals under differential privacy},
  author={Covington, Christian and He, Xi and Honaker, James and Kamath, Gautam},
  journal={arXiv preprint arXiv:2110.14465},
  year={2021}
}

@inproceedings{bassily2014private,
  title={Private empirical risk minimization: Efficient algorithms and tight error bounds},
  author={Bassily, Raef and Smith, Adam and Thakurta, Abhradeep},
  booktitle={2014 IEEE 55th Annual Symposium on Foundations of Computer Science},
  pages={464--473},
  year={2014},
  organization={IEEE}
}

@article{shejwalkar2022recycling,
  title={Recycling Scraps: Improving Private Learning by Leveraging Intermediate Checkpoints},
  author={Shejwalkar, Virat and Ganesh, Arun and Mathews, Rajiv and Thakkar, Om and Thakurta, Abhradeep},
  journal={arXiv preprint arXiv:2210.01864},
  year={2022}
}

@article{williams2010probabilistic,
  title={Probabilistic inference and differential privacy},
  author={Williams, Oliver and McSherry, Frank},
  journal={Advances in neural information processing systems},
  volume={23},
  year={2010}
}

@article{liu2020simple,
  title={Simple and principled uncertainty estimation with deterministic deep learning via distance awareness},
  author={Liu, Jeremiah and Lin, Zi and Padhy, Shreyas and Tran, Dustin and Bedrax Weiss, Tania and Lakshminarayanan, Balaji},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={7498--7512},
  year={2020}
}

@article{papernot2021hyperparameter,
  title={Hyperparameter tuning with renyi differential privacy},
  author={Papernot, Nicolas and Steinke, Thomas},
  journal={arXiv preprint arXiv:2110.03620},
  year={2021}
}

@inproceedings{dwork2006calibrating,
  title={Calibrating noise to sensitivity in private data analysis},
  author={Dwork, Cynthia and McSherry, Frank and Nissim, Kobbi and Smith, Adam},
  booktitle={Theory of Cryptography: Third Theory of Cryptography Conference, TCC 2006, New York, NY, USA, March 4-7, 2006. Proceedings 3},
  pages={265--284},
  year={2006},
  organization={Springer}
}

@inproceedings{dwork2006our,
  title={Our data, ourselves: Privacy via distributed noise generation},
  author={Dwork, Cynthia and Kenthapadi, Krishnaram and McSherry, Frank and Mironov, Ilya and Naor, Moni},
  booktitle={Advances in Cryptology-EUROCRYPT 2006: 24th Annual International Conference on the Theory and Applications of Cryptographic Techniques, St. Petersburg, Russia, May 28-June 1, 2006. Proceedings 25},
  pages={486--503},
  year={2006},
  organization={Springer}
}

@inproceedings{feldman2020does,
  title={Does learning require memorization? a short tale about a long tail},
  author={Feldman, Vitaly},
  booktitle={Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of Computing},
  pages={954--959},
  year={2020}
}

@inproceedings{brown2021memorization,
  title={When is memorization of irrelevant training data necessary for high-accuracy learning?},
  author={Brown, Gavin and Bun, Mark and Feldman, Vitaly and Smith, Adam and Talwar, Kunal},
  booktitle={Proceedings of the 53rd annual ACM SIGACT symposium on theory of computing},
  pages={123--132},
  year={2021}
}

@article{dwork2014algorithmic,
  title={The algorithmic foundations of differential privacy},
  author={Dwork, Cynthia and Roth, Aaron and others},
  journal={Foundations and Trends{\textregistered} in Theoretical Computer Science},
  volume={9},
  number={3--4},
  pages={211--407},
  year={2014},
  publisher={Now Publishers, Inc.}
}

@article{xiao2017fashion,
  title={Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms},
  author={Xiao, Han and Rasul, Kashif and Vollgraf, Roland},
  journal={arXiv preprint arXiv:1708.07747},
  year={2017}
}

@article{bagdasaryan2019differential,
  title={Differential privacy has disparate impact on model accuracy},
  author={Bagdasaryan, Eugene and Poursaeed, Omid and Shmatikov, Vitaly},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{Paszke_PyTorch_An_Imperative_2019,
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and d'Alché-Buc, F. and Fox, E. and Garnett, R.},
pages = {8024--8035},
publisher = {Curran Associates, Inc.},
title = {{PyTorch: An Imperative Style, High-Performance Deep Learning Library}},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf},
year = {2019}
}

@article{opacus,
  title={Opacus: {U}ser-Friendly Differential Privacy Library in {PyTorch}},
  author={Ashkan Yousefpour and Igor Shilov and Alexandre Sablayrolles and Davide Testuggine and Karthik Prasad and Mani Malek and John Nguyen and Sayan Ghosh and Akash Bharadwaj and Jessica Zhao and Graham Cormode and Ilya Mironov},
  journal={arXiv preprint arXiv:2109.12298},
  year={2021}
}

@inproceedings{mironov2017renyi,
  title={R{\'e}nyi differential privacy},
  author={Mironov, Ilya},
  booktitle={2017 IEEE 30th computer security foundations symposium (CSF)},
  pages={263--275},
  year={2017},
  organization={IEEE}
}

@article{karwa2017finite,
  title={Finite sample differentially private confidence intervals},
  author={Karwa, Vishesh and Vadhan, Salil},
  journal={arXiv preprint arXiv:1711.03908},
  year={2017}
}

@inproceedings{ferrando2022parametric,
  title={Parametric bootstrap for differentially private confidence intervals},
  author={Ferrando, Cecilia and Wang, Shufan and Sheldon, Daniel},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1598--1618},
  year={2022},
  organization={PMLR}
}


@article{vijh2020stock,
  title={Stock closing price prediction using machine learning techniques},
  author={Vijh, Mehar and Chandola, Deeksha and Tikkiwal, Vinay Anand and Kumar, Arun},
  journal={Procedia computer science},
  volume={167},
  pages={599--606},
  year={2020},
  publisher={Elsevier}
}

@article{tagasovska2019single,
  title={Single-model uncertainties for deep learning},
  author={Tagasovska, Natasa and Lopez-Paz, David},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}


% SC Bounds

@article{renggli2021evaluating,
  title={Evaluating Bayes error estimators on real-world datasets with FeeBee},
  author={Renggli, Cedric and Rimanic, Luka and Hollenstein, Nora and Zhang, Ce},
  journal={arXiv preprint arXiv:2108.13034},
  year={2021}
}

@article{wiener2011agnostic,
  title={Agnostic selective classification},
  author={Wiener, Yair and El-Yaniv, Ran},
  journal={Advances in neural information processing systems},
  volume={24},
  year={2011}
}

@inproceedings{carlini2022membership,
  title={Membership inference attacks from first principles},
  author={Carlini, Nicholas and Chien, Steve and Nasr, Milad and Song, Shuang and Terzis, Andreas and Tramer, Florian},
  booktitle={2022 IEEE Symposium on Security and Privacy (SP)},
  pages={1897--1914},
  year={2022},
  organization={IEEE}
}


@article{atchison1980logistic,
  title={Logistic-normal distributions: Some properties and uses},
  author={Atchison, Jhon and Shen, Sheng M},
  journal={Biometrika},
  volume={67},
  number={2},
  pages={261--272},
  year={1980},
  publisher={Oxford University Press}
}

@article{tsagris2014folded,
  title={On the folded normal distribution},
  author={Tsagris, Michail and Beneki, Christina and Hassani, Hossein},
  journal={Mathematics},
  volume={2},
  number={1},
  pages={12--28},
  year={2014},
  publisher={MDPI}
}

@article{ni2019calibration,
  title={On the calibration of multiclass classification with rejection},
  author={Ni, Chenri and Charoenphakdee, Nontawat and Honda, Junya and Sugiyama, Masashi},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{charoenphakdee2021classification,
  title={Classification with rejection based on cost-sensitive classification},
  author={Charoenphakdee, Nontawat and Cui, Zhenghang and Zhang, Yivan and Sugiyama, Masashi},
  booktitle={International Conference on Machine Learning},
  pages={1507--1517},
  year={2021},
  organization={PMLR}
}

@inproceedings{cortes2016learning,
  title={Learning with rejection},
  author={Cortes, Corinna and DeSalvo, Giulia and Mohri, Mehryar},
  booktitle={Algorithmic Learning Theory: 27th International Conference, ALT 2016, Bari, Italy, October 19-21, 2016, Proceedings 27},
  pages={67--82},
  year={2016},
  organization={Springer}
}

@inproceedings{schreuder2021classification,
  title={Classification with abstention but without disparities},
  author={Schreuder, Nicolas and Chzhen, Evgenii},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={1227--1236},
  year={2021},
  organization={PMLR}
}

@article{fisch2022calibrated,
  title={Calibrated selective classification},
  author={Fisch, Adam and Jaakkola, Tommi and Barzilay, Regina},
  journal={arXiv preprint arXiv:2208.12084},
  year={2022}
}

@book{kalos2009monte,
  title={Monte carlo methods},
  author={Kalos, Malvin H and Whitlock, Paula A},
  year={2009},
  publisher={John Wiley \& Sons}
}

@inproceedings{lee2021fair,
  title={Fair selective classification via sufficiency},
  author={Lee, Joshua K and Bu, Yuheng and Rajan, Deepta and Sattigeri, Prasanna and Panda, Rameswar and Das, Subhro and Wornell, Gregory W},
  booktitle={International conference on machine learning},
  pages={6076--6086},
  year={2021},
  organization={PMLR}
}

@inproceedings{pugnana2023auc,
  title={AUC-based selective classification},
  author={Pugnana, Andrea and Ruggieri, Salvatore},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2494--2514},
  year={2023},
  organization={PMLR}
}

@article{bishop2006pattern,
  title={Pattern recognition and machine learning},
  author={Bishop, Christopher M},
  journal={Springer},
  volume={2},
  pages={1122--1128},
  year={2006}
}

@article{cattelan2023fix,
  title={How to fix a broken confidence estimator: Evaluating post-hoc methods for selective classification with deep neural networks},
  author={Cattelan, Lu{\'\i}s Felipe Prates and Silva, Danilo},
  year={2023}
}

@inproceedings{ding2020revisiting,
  title={Revisiting the evaluation of uncertainty estimation and its application to explore model complexity-uncertainty trade-off},
  author={Ding, Yukun and Liu, Jinglan and Xiong, Jinjun and Shi, Yiyu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
  pages={4--5},
  year={2020}
}

@inproceedings{rabanser2025confidential,
  title = {Confidential Guardian: Cryptographically Prohibiting the Abuse of Model Abstention},
  author = {Stephan Rabanser and Ali Shahin Shamsabadi and Olive Franzese and Xiao Wang and Adrian Weller and Nicolas Papernot},
  year = {2025},
  booktitle = {Proceedings of the 42nd International Conference on Machine Learning},
}

@article{rabanser2025gatekeeper,
  title={{I Know What I Don't Know: Improving Model Cascades Through Confidence Tuning}},
  author={Rabanser, Stephan and Rauschmayr, Nathalie and Kulshrestha, Achin and Poklukar, Petra and Jitkrittum, Wittawat and Augenstein, Sean and Wang, Congchao and Tombari, Federico},
  journal={arXiv preprint arXiv:2502.19335},
  year={2025}
}

@article{rabanser2025what,
  title={What Does It Take to Build a Performant Selective Classifier?},
  author={Rabanser, Stephan and Papernot, Nicolas},
  year={2025},
  journal={In Submission}
}

@article{tselentis2023usefulness,
  title={The usefulness of artificial intelligence for safety assessment of different transport modes},
  author={Tselentis, Dimitrios I and Papadimitriou, Eleonora and van Gelder, Pieter},
  journal={Accident Analysis \& Prevention},
  volume={186},
  pages={107034},
  year={2023},
  publisher={Elsevier}
}

@article{mehrabi2021survey,
  title={A survey on bias and fairness in machine learning},
  author={Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram},
  journal={ACM computing surveys (CSUR)},
  volume={54},
  number={6},
  pages={1--35},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{chen2019looks,
  title={This looks like that: deep learning for interpretable image recognition},
  author={Chen, Chaofan and Li, Oscar and Tao, Daniel and Barnett, Alina and Rudin, Cynthia and Su, Jonathan K},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{rudin2019stop,
  title={Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead},
  author={Rudin, Cynthia},
  journal={Nature machine intelligence},
  volume={1},
  number={5},
  pages={206--215},
  year={2019},
  publisher={Nature Publishing Group UK London}
}

@article{gal2016uncertainty,
  title={Uncertainty in deep learning},
  author={Gal, Yarin and others},
  year={2016},
  publisher={phd thesis, University of Cambridge}
}

@article{szegedy2013intriguing,
  title={Intriguing properties of neural networks},
  author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  journal={arXiv preprint arXiv:1312.6199},
  year={2013}
}

@article{rahimian2022frameworks,
  title={Frameworks and results in distributionally robust optimization},
  author={Rahimian, Hamed and Mehrotra, Sanjay},
  journal={Open Journal of Mathematical Optimization},
  volume={3},
  pages={1--85},
  year={2022}
}

@article{yaghini2024regulation,
  title={Regulation games for trustworthy machine learning},
  author={Yaghini, Mohammad and Liu, Patty and Boenisch, Franziska and Papernot, Nicolas},
  journal={arXiv preprint arXiv:2402.03540},
  year={2024}
}

@article{lo2020ethical,
  title={Ethical principles in machine learning and artificial intelligence: cases from the field and possible ways forward},
  author={Lo Piano, Samuele},
  journal={Humanities and Social Sciences Communications},
  volume={7},
  number={1},
  pages={1--7},
  year={2020},
  publisher={Palgrave}
}

@article{li2023trustworthy,
  title={Trustworthy AI: From principles to practices},
  author={Li, Bo and Qi, Peng and Liu, Bo and Di, Shuai and Liu, Jingen and Pei, Jiquan and Yi, Jinfeng and Zhou, Bowen},
  journal={ACM Computing Surveys},
  volume={55},
  number={9},
  pages={1--46},
  year={2023},
  publisher={ACM New York, NY}
}

@inproceedings{pervaiz2019examining,
  title={Examining the challenges in development data pipeline},
  author={Pervaiz, Fahad and Vashistha, Aditya and Anderson, Richard},
  booktitle={Proceedings of the 2nd ACM SIGCAS Conference on Computing and Sustainable Societies},
  pages={13--21},
  year={2019}
}

@article{wiens2019no,
  title={Do no harm: a roadmap for responsible machine learning for health care},
  author={Wiens, Jenna and Saria, Suchi and Sendak, Mark and Ghassemi, Marzyeh and Liu, Vincent X and Doshi-Velez, Finale and Jung, Kenneth and Heller, Katherine and Kale, David and Saeed, Mohammed and others},
  journal={Nature medicine},
  volume={25},
  number={9},
  pages={1337--1340},
  year={2019},
  publisher={Nature Publishing Group US New York}
}

@article{amodei2016concrete,
  title={Concrete problems in AI safety},
  author={Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Man{\'e}, Dan},
  journal={arXiv preprint arXiv:1606.06565},
  year={2016}
}

@article{gawlikowski2023survey,
  title={A survey of uncertainty in deep neural networks},
  author={Gawlikowski, Jakob and Tassi, Cedrique Rovile Njieutcheu and Ali, Mohsin and Lee, Jongseok and Humt, Matthias and Feng, Jianxiang and Kruspe, Anna and Triebel, Rudolph and Jung, Peter and Roscher, Ribana and others},
  journal={Artificial Intelligence Review},
  volume={56},
  number={Suppl 1},
  pages={1513--1589},
  year={2023},
  publisher={Springer}
}

@inproceedings{papernot2017practical,
  title={Practical black-box attacks against machine learning},
  author={Papernot, Nicolas and McDaniel, Patrick and Goodfellow, Ian and Jha, Somesh and Celik, Z Berkay and Swami, Ananthram},
  booktitle={Proceedings of the 2017 ACM on Asia conference on computer and communications security},
  pages={506--519},
  year={2017}
}

@article{hullermeier2021aleatoric,
  title={Aleatoric and epistemic uncertainty in machine learning: An introduction to concepts and methods},
  author={H{\"u}llermeier, Eyke and Waegeman, Willem},
  journal={Machine learning},
  volume={110},
  number={3},
  pages={457--506},
  year={2021},
  publisher={Springer}
}

@article{breiman1996bagging,
  title={Bagging predictors},
  author={Breiman, Leo},
  journal={Machine learning},
  volume={24},
  pages={123--140},
  year={1996},
  publisher={Springer}
}

@article{shafer2008tutorial,
  title={A tutorial on conformal prediction.},
  author={Shafer, Glenn and Vovk, Vladimir},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={3},
  year={2008}
}

@article{fontana2023conformal,
  title={Conformal prediction: a unified review of theory and new challenges},
  author={Fontana, Matteo and Zeni, Gianluca and Vantini, Simone},
  journal={Bernoulli},
  volume={29},
  number={1},
  pages={1--23},
  year={2023},
  publisher={Bernoulli Society for Mathematical Statistics and Probability}
}

@article{geyer1992practical,
  title={Practical markov chain monte carlo},
  author={Geyer, Charles J},
  journal={Statistical science},
  pages={473--483},
  year={1992},
  publisher={JSTOR}
}

@article{blei2017variational,
  title={Variational inference: A review for statisticians},
  author={Blei, David M and Kucukelbir, Alp and McAuliffe, Jon D},
  journal={Journal of the American statistical Association},
  volume={112},
  number={518},
  pages={859--877},
  year={2017},
  publisher={Taylor \& Francis}
}

@inproceedings{zadrozny2002transforming,
  title={Transforming classifier scores into accurate multiclass probability estimates},
  author={Zadrozny, Bianca and Elkan, Charles},
  booktitle={Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={694--699},
  year={2002}
}

@book{shalev2014understanding,
  title={Understanding machine learning: From theory to algorithms},
  author={Shalev-Shwartz, Shai and Ben-David, Shai},
  year={2014},
  publisher={Cambridge university press}
}

@book{devroye2013probabilistic,
  title={A probabilistic theory of pattern recognition},
  author={Devroye, Luc and Gy{\"o}rfi, L{\'a}szl{\'o} and Lugosi, G{\'a}bor},
  volume={31},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@inproceedings{zhu2022rethinking,
  title={Rethinking confidence calibration for failure prediction},
  author={Zhu, Fei and Cheng, Zhen and Zhang, Xu-Yao and Liu, Cheng-Lin},
  booktitle={European conference on computer vision},
  pages={518--536},
  year={2022},
  organization={Springer}
}

@article{kull2019beyond,
  title={Beyond temperature scaling: Obtaining well-calibrated multi-class probabilities with dirichlet calibration},
  author={Kull, Meelis and Perello Nieto, Miquel and K{\"a}ngsepp, Markus and Silva Filho, Telmo and Song, Hao and Flach, Peter},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{zadrozny2001obtaining,
  title={Obtaining calibrated probability estimates from decision trees and naive bayesian classifiers},
  author={Zadrozny, Bianca and Elkan, Charles},
  booktitle={Icml},
  volume={1},
  number={05},
  year={2001}
}

@article{angelopoulos2021gentle,
  title={A gentle introduction to conformal prediction and distribution-free uncertainty quantification},
  author={Angelopoulos, Anastasios N and Bates, Stephen},
  journal={arXiv preprint arXiv:2107.07511},
  year={2021}
}

@article{gollakota2025loss,
  title={When does a predictor know its own loss?},
  author={Gollakota, Aravind and Gopalan, Parikshit and Karan, Aayush and Peale, Charlotte and Wieder, Udi},
  journal={arXiv preprint arXiv:2502.20375},
  year={2025}
}

@inproceedings{hebert2018multicalibration,
  title={Multicalibration: Calibration for the (computationally-identifiable) masses},
  author={H{\'e}bert-Johnson, Ursula and Kim, Michael and Reingold, Omer and Rothblum, Guy},
  booktitle={International Conference on Machine Learning},
  pages={1939--1948},
  year={2018},
  organization={PMLR}
}

@article{muller1997integral,
  title={Integral probability metrics and their generating classes of functions},
  author={M{\"u}ller, Alfred},
  journal={Advances in applied probability},
  volume={29},
  number={2},
  pages={429--443},
  year={1997},
  publisher={Cambridge University Press}
}

@article{wei2021learning,
  title={Learning with noisy labels revisited: A study using real-world human annotations},
  author={Wei, Jiaheng and Zhu, Zhaowei and Cheng, Hao and Liu, Tongliang and Niu, Gang and Liu, Yang},
  journal={arXiv preprint arXiv:2110.12088},
  year={2021}
}

@article{zagoruyko2016wide,
  title={Wide residual networks},
  author={Zagoruyko, Sergey and Komodakis, Nikos},
  journal={arXiv preprint arXiv:1605.07146},
  year={2016}
}
@article{hendrycks2019robustness,
  title={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},
  author={Dan Hendrycks and Thomas Dietterich},
  journal={Proceedings of the International Conference on Learning Representations},
  year={2019}
}

@inproceedings{koh2021wilds,
  title={Wilds: A benchmark of in-the-wild distribution shifts},
  author={Koh, Pang Wei and Sagawa, Shiori and Marklund, Henrik and Xie, Sang Michael and Zhang, Marvin and Balsubramani, Akshay and Hu, Weihua and Yasunaga, Michihiro and Phillips, Richard Lanas and Gao, Irena and others},
  booktitle={International conference on machine learning},
  pages={5637--5664},
  year={2021},
  organization={PMLR}
}

@article{ovadia2019can,
  title={Can you trust your model's uncertainty? evaluating predictive uncertainty under dataset shift},
  author={Ovadia, Yaniv and Fertig, Emily and Ren, Jie and Nado, Zachary and Sculley, David and Nowozin, Sebastian and Dillon, Joshua and Lakshminarayanan, Balaji and Snoek, Jasper},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{ding2024hybrid,
  title={Hybrid llm: Cost-efficient and quality-aware query routing},
  author={Ding, Dujian and Mallick, Ankur and Wang, Chi and Sim, Robert and Mukherjee, Subhabrata and Ruhle, Victor and Lakshmanan, Laks VS and Awadallah, Ahmed Hassan},
  journal={arXiv preprint arXiv:2404.14618},
  year={2024}
}

@article{chen2023frugalgpt,
  title={Frugalgpt: How to use large language models while reducing cost and improving performance},
  author={Chen, Lingjiao and Zaharia, Matei and Zou, James},
  journal={arXiv preprint arXiv:2305.05176},
  year={2023}
}

@article{shnitzer2023large,
  title={Large language model routing with benchmark datasets},
  author={Shnitzer, Tal and Ou, Anthony and Silva, M{\'\i}rian and Soule, Kate and Sun, Yuekai and Solomon, Justin and Thompson, Neil and Yurochkin, Mikhail},
  journal={arXiv preprint arXiv:2309.15789},
  year={2023}
}

@article{nie2024online,
  title={Online cascade learning for efficient inference over streams},
  author={Nie, Lunyiu and Ding, Zhimin and Hu, Erdong and Jermaine, Christopher and Chaudhuri, Swarat},
  journal={arXiv preprint arXiv:2402.04513},
  year={2024}
}

@article{geng2023survey,
  title={A survey of confidence estimation and calibration in large language models},
  author={Geng, Jiahui and Cai, Fengyu and Wang, Yuxia and Koeppl, Heinz and Nakov, Preslav and Gurevych, Iryna},
  journal={arXiv preprint arXiv:2311.08298},
  year={2023}
}

@article{azaria2023internal,
  title={The internal state of an LLM knows when it's lying},
  author={Azaria, Amos and Mitchell, Tom},
  journal={arXiv preprint arXiv:2304.13734},
  year={2023}
}

@article{liu2024uncertainty,
  title={Uncertainty estimation and quantification for llms: A simple supervised approach},
  author={Liu, Linyu and Pan, Yu and Li, Xiaocheng and Chen, Guanting},
  journal={arXiv preprint arXiv:2404.15993},
  year={2024}
}

@article{lin2022teaching,
  title={Teaching models to express their uncertainty in words},
  author={Lin, Stephanie and Hilton, Jacob and Evans, Owain},
  journal={arXiv preprint arXiv:2205.14334},
  year={2022}
}

@article{mahaut2024factual,
  title={Factual confidence of LLMs: On reliability and robustness of current estimators},
  author={Mahaut, Mat{\'e}o and Aina, Laura and Czarnowska, Paula and Hardalov, Momchil and M{\"u}ller, Thomas and M{\`a}rquez, Llu{\'\i}s},
  journal={arXiv preprint arXiv:2406.13415},
  year={2024}
}

@inproceedings{lorenz2023certifiers,
  title={Certifiers make neural networks vulnerable to availability attacks},
  author={Lorenz, Tobias and Kwiatkowska, Marta and Fritz, Mario},
  booktitle={Proceedings of the 16th ACM Workshop on Artificial Intelligence and Security},
  pages={67--78},
  year={2023}
}

@book{berger2013statistical,
  title={Statistical decision theory and Bayesian analysis},
  author={Berger, James O},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@article{kirchhof2025position,
  title={Position: Uncertainty quantification needs reassessment for large-language model agents},
  author={Kirchhof, Michael and Kasneci, Gjergji and Kasneci, Enkelejda},
  journal={arXiv preprint arXiv:2505.22655},
  year={2025}
}